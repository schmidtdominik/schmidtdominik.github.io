<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Why `tf.data` is much better than `feed_dict` and how to build a simple data pipeline in 5 minutes. - Dominik Schmidt</title>
  <meta name="author" content="Dominik Schmidt">
  <meta name="theme-color" content="#52D681"/>

  <link rel=preload href="css/BIG JOHN.otf">

  <meta property="og:title" content="Why tf.data is much better than feed_dict and how to build a simple data pipeline in 5 minutes."/>
  <meta property='og:type' content='article'/>
  <meta property="og:image" content="assets/cover.png"/>
  <meta property="og:url" content="http://dominikschmidt.xyz/tensorflow-data-pipeline"/>
  <!--<meta property="og:description" content="Most beginner tensorflow tutorials introduce the reader to the feed_dict method of loading data into your model where data is passed to tensorflow through the tf.Session.run() or tf.Tensor.eval() function calls. There is, however, a much better and almost easier way of doing this. Using the tf.data API you can create high-performance data pipelines in just a few lines of code."/>-->



  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123900161-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-123900161-1');
  </script>

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <script defer src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
           CommonHTML: {
             scale: (MathJax.Hub.Browser.isChrome ? 100 : 100)
           }
         });


  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>


  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="../css/normalize.css">
  <link rel="stylesheet" href="../css/skeleton.css">
  <link rel="stylesheet" href="../css/main.css">
  <link rel="stylesheet" href="../css/article.css">

  <link rel="stylesheet" href="../highlight/styles/atom-one-light.css"><!--foundation/hopscotch-->
  <script src="../highlight/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="../images/favicon.png">

  <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us19.list-manage.com","uuid":"728374c3215a28cdf09e2b11c","lid":"eeb0dbccb1","uniqueMethods":true}) })</script>
</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <div class="row">
      <div style="margin-top: 8%">
          <h1>
            <a href="../index.html">
              <span id="title">
                Dominik Schmidt
              </span>
            </a>
            <!--<a href="index.html">
              <span id="by-me">

              </span>
            </a>-->
          </h1>
        <hr>
        <nav>
          <span style="display: inline-block;" ><a class="navitem" href="../index.html"><i class="far fa-newspaper"></i>&nbsp;Reads</a></span>
          <span style="display: inline-block;" ><a class="navitem" href="../datasets.html"><i class="fas fa-sitemap"></i>&nbsp;Datasets</a></span>
          <span style="display: inline-block;" ><a class="navitem" href="../about.html"><i class="fas fa-map-marker-alt"></i>&nbsp;About</a></span>

        </nav>
      </div>
    </div>
  </div>

  <div class="container article">
      <div id='header-box'>


        <!--START OF HEADING-->
        <div style="display:flex;justify-content:center;align-items:center;">
          <video autoplay="true" id="header-img" poster="assets/cover.png" autoplay loop playsinline muted>
                        <source src="assets/cover.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video>
        </div>


        <div id="header-text">
          <h1 class="article-title">
            Why <code>tf.data</code> is much better than <code>feed_dict</code> and how to build a simple data pipeline in 5 minutes.
          </h1>
          <time datetime="2018-08-27 00:00:00">August 27, 2018 ⧗ 8 minute read</time><br>
        </div>
      </div>
      <!--END OF HEADING-->

      <span class="article-text">
        <div id="index"><a href=#implementing-a-minimal-image-pipeline-in-5-minutes> → Implementing a minimal image pipeline in 5 minutes</a><br><a href=#defining-the-computation-graph>&emsp; → Defining the computation graph</a><br><a href=#running-the-session>&emsp; → Running the session</a><br><a href=#a-more-complete-data-pipeline> → A more complete data pipeline</a><br><a href=#shuffle>&emsp; → Shuffle</a><br><a href=#data-augmentation>&emsp; → Data augmentation</a><br><a href=#labels>&emsp; → Labels</a></div><br><hr>
Most beginner tensorflow tutorials introduce the reader to the <code>feed_dict</code> method of loading data into your model where data is passed to tensorflow through the <code>tf.Session.run()</code> or <code>tf.Tensor.eval()</code> function calls. There is, however, a much better and almost easier way of doing this. Using the <code>tf.data</code> API you can create high-performance data pipelines in just a few lines of code.  <br>
<br>

In a naive <code>feed_dict</code> pipeline the GPU always sits by idly whenever it has to wait for the CPU to provide it with the next batch of data.<br>

<div class="image-center-wrapper"><img src="assets/feed_dict_pipeline.png" style="width: 77%;" class="inline-image image-center    no-border-radius"></div>
A <code>tf.data</code> pipeline, however, can prefetch the next batches asynchronously to minimize the total idle time. You can further speed up the pipeline by parallelizing the loading and preprocessing operations.<br>

<div class="image-center-wrapper"><img src="assets/tf_data_pipeline.png" style="width: 77%;" class="inline-image image-center    no-border-radius"></div><h2 id="implementing-a-minimal-image-pipeline-in-5-minutes"> Implementing a minimal image pipeline in 5 minutes</h2><br>

To build a simple data pipeline you need two objects. A <code>tf.data.Dataset</code> stores your dataset and a <code>tf.data.Iterator</code> allows you to extract items from your dataset one-by-one.<br>

A <code>tf.data.Dataset</code> for an image pipeline could (schematically) look like this:
<div class="code-wrapper"><pre><code>[
    [Tensor(image), Tensor(label)],
    [Tensor(image), Tensor(label)],
    ...
]
</code></pre></div>
You can then use a <code>tf.data.Iterator</code> to retrieve image-label pairs one by one. In practice, multiple image-label pairs would be batched together so that the iterator pulls out one entire batch at a time. <br>
<br>

A dataset can be created either from a source (like a list of filenames in Python) or by applying a transformation to an existing dataset. Here are some examples of possible transformations:<br>
<br>

<ul>
<li><code>Dataset(<em>list of image files</em>)</code> → <code>Dataset(<em>actual images</em>)</code></li>
<li><code>Dataset(<em>6400 images</em>)</code> → <code>Dataset(<em>64 batches with 100 images each</em>)</code></li>
<li><code>Dataset(<em>list of audio files</em>)</code> → <code>Dataset(<em>shuffled list of audio files</em>)</code></li>
</ul><br>
<h3 id="defining-the-computation-graph"> Defining the computation graph</h3>
A minimal data pipeline for images could look like this:<br>

<div class="image-center-wrapper"><img src="assets/minimal_pipeline.png" style="width: 70%;" class="inline-image image-center    no-border-radius"></div>
<strong>All of the following code is placed in your computation graph definition along with the model, loss, optimizer,...</strong> First create a tensor from a list of files.<br>

<div class="code-wrapper"><pre><code># define list of files
files = ['a.png', 'b.png', 'c.png', 'd.png']
    
# create a dataset from filenames
dataset = tf.data.Dataset.from_tensor_slices(files)
</code></pre></div>
Now define a function to load an image (as a tensor) from its path and use <code>tf.data.Dataset.map()</code> to apply this function to all elements (file paths) in the dataset.<sup><a id="ref1ref" href="#ref1">[1]</a></sup> You can also add a <code>num_parallel_calls=n</code> argument to <code>map()</code> to parallelize the function calls.<br>

<div class="code-wrapper"><pre><code># <span class="highlight"><a href="https://cs230-stanford.github.io/tensorflow-input-data.html#building-an-image-data-pipeline">Source</a></span>
def load_image(path):
    image_string = tf.read_file(path)

    # Don't use tf.image.decode_image, or the output shape will be undefined
    image = tf.image.decode_jpeg(image_string, channels=3)

    # This will convert to float values in [0, 1]
    image = tf.image.convert_image_dtype(image, tf.float32)

    image = tf.image.resize_images(image, [image_size, image_size])
    return image


# Apply the function load_image to each filename in the dataset
dataset = dataset.map(load_image, num_parallel_calls=8)
</code></pre></div>
Next use <code>tf.data.Dataset.batch()</code> to create batches:
<div class="code-wrapper"><pre><code># Create batches of 64 images each
dataset = dataset.batch(64)
</code></pre></div>
You may also want to add <code>tf.data.Dataset.prefetch(buffer_size)</code> to the end of your pipeline. This ensures that the next batch is always immediately available to the GPU and reduces GPU starvation as mentioned above. <code>buffer_size</code> is the number of batches that should be prefetched. <code>buffer_size=1</code> is usually sufficient although in some cases, especially when the processing time per batch varies, it can help to increase it.<br>

<div class="code-wrapper"><pre><code>dataset = dataset.prefetch(buffer_size=1)
</code></pre></div>
Finally, create an iterator to allow us to iterate through the dataset. There are different types of iterators available. For most purposes the initializable iterator is recommended.<br>

<div class="code-wrapper"><pre><code>iterator = dataset.make_initializable_iterator()
</code></pre></div>
Now call <code>tf.data.Iterator.get_next()</code> to create a placeholder-tensor that tensorflow fills with the next batch of images <strong>every time it is evaluated.</strong><br>

<div class="code-wrapper"><pre><code>batch_of_images = iterator.get_next()
</code></pre></div>
If you're switching from <code>feed_dict</code>, <code>batch_of_images</code> replaces your previous placeholder variable. <br>
<h3 id="running-the-session"> Running the session</h3>
Now run your model as usual but make sure to evaluate the <code>iterator.initializer</code> op <strong>before</strong> every epoch and catch the <code>tf.errors.OutOfRangeError</code> exception <strong>after</strong> every epoch.<br>

<div class="code-wrapper"><pre><code>with tf.Session() as session:
    
    for i in range(epochs): 
        session.run(iterator.initializer)
        
        try:
            # Go through the entire dataset
            while True:
                image_batch = session.run(batch_of_images)
                
        except tf.errors.OutOfRangeError:
            print('End of Epoch.')
</code></pre></div>
<div class="specialbox hintbox"><i class="fas fa-info-circle"></i>&ensp;
The program <code>nvidia-smi</code> allows you to monitor your GPU utilization and can help you understand bottlenecks in your data pipeline. The average GPU utilization should usually be above 70-80%.
</div><br>
<h2 id="a-more-complete-data-pipeline"> A more complete data pipeline</h2>
<div class="image-center-wrapper"><img src="assets/complete_pipeline.png" style="width: 77%;" class="inline-image image-center    "></div><h3 id="shuffle"> Shuffle</h3>
Use <code>tf.data.Dataset.shuffle()</code> to shuffle the filenames. The argument specifies how many elements should be shuffled at a time. In general, it's recommended to shuffle the entire list at once. <a href="https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle/48096625#48096625">See this answer on Stackoverflow</a><br>

<div class="code-wrapper"><pre><code>dataset = tf.data.Dataset.from_tensor_slices(files)
dataset = dataset.shuffle(len(files))
</code></pre></div><h3 id="data-augmentation"> Data augmentation</h3>
You can use the functions <code>tf.image.random_flip_left_right()</code>, <code>tf.image.random_brightness()</code>, <code>tf.image.random_saturation()</code> to perform simple data augmentation on your images. <sup><a id="ref1ref" href="#ref1">[1]</a></sup><br>

<div class="code-wrapper"><pre><code># <span class="highlight"><a href="https://cs230-stanford.github.io/tensorflow-input-data.html#building-an-image-data-pipeline">Source</a></span>
def train_preprocess(image):
    image = tf.image.random_flip_left_right(image)

    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)
    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)
    # Make sure the image is still in [0, 1]
    image = tf.clip_by_value(image, 0.0, 1.0)

    return image
</code></pre></div><h3 id="labels"> Labels</h3>
To load labels (or other metadata) along your images simply include them when creating the intial dataset:
<div class="code-wrapper"><pre><code># <code>files</code> is a python list of image filenames
# <code>labels</code> is a numpy array with label data for each image
dataset = tf.data.Dataset.from_tensor_slices((files, labels))
</code></pre></div>
Make sure any functions that you apply to your dataset with <code>.map()</code> allow label data to pass through:<br>

<div class="code-wrapper"><pre><code>def load_image(path, label):
    # load image
    
    return image, label

dataset = dataset.map(load_image)
</code></pre></div>

<div class="specialbox emailbox">
    <strong>Any questions? Suggestions? Clarification needed?</strong><br>
    Telegram: <a href="https://t.me/schmidtdominik">@schmidtdominik</a><br>
    Email: <a id="email" target="_blank">&#115;&#099;&#104;&#109;&#105;&#100;&#116;&#100;&#111;&#109;&#105;&#110;&#105;&#107;&#051;&#048;&#032;[&#097;&#116;]&#032;&#103;&#109;&#097;&#105;&#108;&#046;&#032;[&#100;&#111;&#116;]&#032;&#099;&#111;&#109;</a><br>
    Reddit: <a href="https://reddit.com/u/dominik_schmidt">u/dominik_schmidt</a><br>
</div>
<script type="text/javascript">
    var string1 = "schmidtdominik30";
    var string2 = "@";
    var string3 = "gmail.com";
    var string4 = string1 + string2 + string3;
    document.getElementById('email').innerHTML = string4;
    document.getElementById('email').href = "mailto:" + string4 + "?subject=Hi!";
</script>

<section id="article_footer"><div class="further-reading"><h2>Further Reading</h2><br><ul><li><a href="https://docs.google.com/presentation/d/16kHNtQslt-yuJ3w8GIx-eEH6t_AvFeQOchqGRFpAD7U/edit">Google Slides presentation by one of the developers of tf.data</a></li><li><a href="https://cs230-stanford.github.io/tensorflow-input-data.html">Stanford CS230 - Article about tf.data</a></li><li><a href="https://www.tensorflow.org/guide/datasets">tensorflow.org - Importing Data</a></li><li><a href="https://www.tensorflow.org/performance/datasets_performance">tensorflow.org - Input Pipeline Performance Guide</a></li></ul></div><h2>References</h2><br><ol class="references"><li><span id="ref1"><a href="https://cs230-stanford.github.io/tensorflow-input-data.html#building-an-image-data-pipeline">Stanford CS230 - Article about tf.data</a></span> <a href="#ref1ref""><i class="references-return fas fa-caret-left"></i></a></li></ol></section>
      </span>
  </div>

  <br><br>

  <footer class="container">
    <span><i class="fas fa-copyright"></i> 2018 Dominik Schmidt</span><br>
  </footer>

  <br>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
